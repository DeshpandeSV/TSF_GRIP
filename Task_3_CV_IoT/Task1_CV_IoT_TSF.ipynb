{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision and Internet of Things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Object Detection / Optical Character Recognition (ORC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description : Implement an object detector which identifies the classes of the objects in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author : Shivam Deshpande"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "### Here we have used MobileNet SSD and dnn module in openCV to build fast and efficient object detector of deep learning\n",
    "### We load the pre-trained model by giving it the different class labels or objects\n",
    "### Algorithm detects labels based on the provided data\n",
    "### Then it draws the bounding box around the image with the predicted class label and the confidence value (Confidence value is nothing but the probability of detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model\n",
      "Model is loaded\n"
     ]
    }
   ],
   "source": [
    "# loading the serialized model from disc\n",
    "# It is a pre-trained caffe network\n",
    "\n",
    "print(\"Loading the model\")\n",
    "net = cv2.dnn.readNetFromCaffe('MobileNetSSD_deploy.prototxt.txt', 'MobileNetSSD_deploy.caffemodel')\n",
    "print(\"Model is loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the objects or class labels which mobilenet ssd was trained to detect\n",
    "# They generate bounding boxes with colors for each category of object\n",
    "\n",
    "classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \n",
    "          \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image of which the objects we have to detect\n",
    "\n",
    "image = cv2.imread('image2.jpg')\n",
    "image = cv2.resize(image, (500,500))\n",
    "cv2.imshow('detected',image)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting height and width and calculating 500x500 blob from image\n",
    "# We will be feeding this blob forward through the network\n",
    "\n",
    "(h, w) = image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(image, 0.007843, (500,500), 127.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing object detection\n"
     ]
    }
   ],
   "source": [
    "# Here first we will set our blob as input to the network\n",
    "# Then we compute the forward pass for the input and store the result as detections\n",
    "\n",
    "print('processing object detection')\n",
    "net.setInput(blob)\n",
    "detections = net.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label predictions, boxing objects and displaying probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description\n",
    "\n",
    "--> We will loop through detections and determine what and where the objects are in the image\n",
    "\n",
    "--> Apply confidence check or probability of prediction\n",
    "\n",
    "--> If the confidence is high enough i.e above the threshold, then\n",
    "\n",
    "       We will display the prediction on the terminal and \n",
    "       \n",
    "       Draw the prediction on the image with text and a colored bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog:91.01%\n",
      "person:50.00%\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0, detections.shape[2]):\n",
    "    # extracting confidence (probability of prediction)\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    # filter out weak detections by ensuring the confidence is greater than minimum confidence\n",
    "    if confidence > 0.3:\n",
    "        \n",
    "        idx = int(detections[0 ,0, i, 1]) # extract the index of class label from detections\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h]) # compute the bounding box around the detected object\n",
    "        \n",
    "        # extract the (x,y) co-ordinates of the box that we will use for drawing the rectangle and displaying the text\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\") \n",
    "        \n",
    "        # build a text label containing class label and confidence\n",
    "        label = \"{}:{:.2f}%\".format(classes[idx], confidence * 100)\n",
    "        \n",
    "        # print to the terminal using the label\n",
    "        print(\"{}\".format(label))\n",
    "        \n",
    "        # draw colored rectangle around the object using the previously extracted (x,y) co-ordinated\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), colors[idx], 2)\n",
    "        \n",
    "        # Normally we want to display the text above the rectangle but if there is no room\n",
    "        # display it just below the top of the rectangle\n",
    "        y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "        \n",
    "        # overlay the coloerd text onto the image using calculated y value \n",
    "        cv2.putText(image, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[idx], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the resulting output image\n",
    "cv2.imshow('output', image)\n",
    "cv2.waitKey(6000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now check this with other images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion : We have implemented object detection using MobileNet SSD and dnn module of cv2 that detects different class labels in image with bounded box, label name and confidence value based on the data given to the loaded pre-trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
